{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\FullStack_Data\\\\MACHINE_LEARNING\\\\PROJECTS\\\\MLPROJECT_part_prediction\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\FullStack_Data\\\\MACHINE_LEARNING\\\\PROJECTS\\\\MLPROJECT_part_prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformConfig:\n",
    "    root_dir : Path\n",
    "    data_dir : Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ML_Part_predict.constants import *\n",
    "from src.ML_Part_predict.utils.common import read_yaml,create_directories\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,config_file_p=CONFIG_FILE_PATH,params_file_p=CONFIG_FILE_PATH,schema_file_p=SCHEMA_FILE_PATH):\n",
    "        self.config=read_yaml(config_file_p)\n",
    "        self.params=read_yaml(params_file_p)\n",
    "        self.schema=read_yaml(schema_file_p)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformConfig:\n",
    "        config=self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transform_config=DataTransformConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_dir=config.data_dir\n",
    "        )\n",
    "        return data_transform_config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ML_Part_predict import logger\n",
    "import pandas as pd\n",
    "class FeatureEngineering:\n",
    "    def __init__(self,config: DataTransformConfig):\n",
    "        logger.info(\"Feature Engineering Started\")\n",
    "        self.config=config\n",
    "\n",
    "    def Random_Sample_imputation(data,feature):\n",
    "        random_sample=data[feature].dropna().sample(data[feature].isnull().sum())               \n",
    "        random_sample.index=data[data[feature].isnull()].index\n",
    "        data.loc[data[feature].isnull(),feature]=random_sample\n",
    "\n",
    "    def handling_outliers(datas,columns):\n",
    "        for i in columns:\n",
    "            q1=datas[i].quantile(0.25)\n",
    "            q3=datas[i].quantile(0.75)\n",
    "            IQR=q3-q1\n",
    "            upper_lim=q3+1.5*IQR\n",
    "            lower_lim=q1-1.5*IQR\n",
    "            datas[i]=datas[i].apply(lambda x:upper_lim if x>upper_lim else lower_lim if x<lower_lim else x)\n",
    "        \n",
    "        return datas\n",
    "\n",
    "    def feature_E(self):\n",
    "        try:\n",
    "            df=pd.read_csv(self.config.data_dir)\n",
    "            logger.info(f\"the columns are {df.columns} and shape is : {df.shape}\")\n",
    "\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            logger.info(f\"duplicated data number: {df.duplicated().sum()}. Duplicates deletion completed\")\n",
    "\n",
    "            df['VehicleYear']=df['VehicleYear'].astype('str')\n",
    "            logger.info(f\"vehicleYear dtype changed to object\")\n",
    "            df['ClaimYear']=df['ClaimDate'].str.split('-').str[0]\n",
    "            logger.info(f\"feature ClaimYear extracted from ClaimDate\")\n",
    "            df['MaintenanceFrequency']=df['MaintenanceFrequency'].str.replace('hours','').astype('Int64')\n",
    "            logger.info(f\"in feature MaintenanceFrequency hours is removed and dtype changed to Int64\")\n",
    "            df['PreviousFailures']=df['PreviousFailures'].astype('Int64')\n",
    "            logger.info(f\"in feature PreviousFailures dtype changed to Int64\")\n",
    "\n",
    "            Random_Sample_imputation(data=df,feature=[i for i in df])\n",
    "            logger.info(f\"replacing null values with random imputation completed...\")\n",
    "\n",
    "            handling_outliers(datas=df,columns=['HoursOfOperation','SettlementAmount','MaintenanceFrequency','PreviousFailures'])\n",
    "            logger.info(f\"Outlier handling completed...\")\n",
    "\n",
    "            df['WarrantyStatus'].replace({'Out of Warranty':'out_of_warranty','In Warranty':'in_warranty'},inplace=True)\n",
    "            logger.info(f\"warranty status values renamed as {df['WarrantyStatus'].unique()}\")\n",
    "            \n",
    "            df=pd.get_dummies(df, columns=['VehicleModel','VehicleYear','PartName','SupplierName','EnvironmentCondition','OperationalIntensity','WarrantyStatus','ClaimYear'], drop_first=True)\n",
    "            df['pass_fail'].replace({'pass': 1, 'fail': 0}, inplace=True)    \n",
    "            logger.info(f\"implementation of pd.dummies completed... \")\n",
    "\n",
    "            df.drop(['ClaimDate'],axis=1,inplace=True)\n",
    "            logger.info(f\"features dropped are : ClaimDate \")\n",
    "\n",
    "            df.to_csv(os.path.join(self.config.root_dir,\"FE_data.csv\"),index=False)\n",
    "            logger.info(f\"Feature Engineering Completed and file saved Successfully\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.ML_Part_predict import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self,config: DataTransformConfig):\n",
    "        logger.info(f\"Data Transformation initiated\")\n",
    "        self.config=config\n",
    "\n",
    "    def train_test_split(self):\n",
    "        try:\n",
    "            logger.info(\"reading the Feature Engineered csv file\")\n",
    "            df=pd.read_csv(self.config.root_dir.FE_data.csv)\n",
    "            logger.info(\"reading the Feature Engineered csv file completed...\")\n",
    "\n",
    "            train,test=train_test_split(df)\n",
    "            logger.info(\"Splitting of train test done...\")\n",
    "\n",
    "            train.to_csv(os.path.join(self.config.root_dir,\"train.csv\"),index=False)\n",
    "            test.to_csv(os.path.join(self.config.root_dir,\"test.csv\"),index=False)\n",
    "\n",
    "            logger.info(train.shape)\n",
    "            logger.info(test.shape)\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    getdatatransform=config.get_data_transformation_config()\n",
    "    featureEng=FeatureEngineering(config=getdatatransform)\n",
    "    featureEng.feature_E()\n",
    "    D_transform=DataTransformation(config=getdatatransform)\n",
    "    D_transform.train_test_split()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
